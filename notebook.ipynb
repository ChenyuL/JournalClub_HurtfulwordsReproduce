{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-d0aba14a-d426-4061-89a3-a44a0e3e6db8",
    "deepnote_app_coordinates": {
     "h": 11,
     "w": 14,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Hurtful Words: Quantifying Biases in Clinical Contextual Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-8a4f4ccb-7915-4acc-b841-e42cb186c146",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Haoran Zhang, Amy X. Lu, Mohamed Abdalla, Matthew McDermott, and Marzyeh Ghassemi. 2020.\n",
    "Hurtful words: quantifying biases in clinical contextual word embeddings.\n",
    "In Proceedings of the ACM Conference on Health, Inference, and Learning (CHIL ’20).\n",
    "Association for Computing Machinery, New York, NY, USA, 110–120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-3fd5194a-8700-439e-a1d9-2b903381d37e",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-f5a2cd1c-2b8b-438f-a9b3-e9a5257227a5",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Why we chose this Paper?\n",
    "\n",
    "- This paper focuses around faireness in NLP tecniques as applied to Biomedical Research.\n",
    "- The research was performed on publicly available data: The Dataset used was [MIMIC III](https://physionet.org/content/mimiciii-demo/1.4/)\n",
    "- The code for the original work is avaiable on (GitHub)[https://github.com/MLforHealth/HurtfulWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-6c793fae-fb71-4ca9-a0ce-856aea5ae126",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Informatics and Biomedical problem:\n",
    "\n",
    "- The contextual word embeddings approach commonly utilized by NLP Transformer models such as BERT can learn to encoding the represent marginalized populations differently.\n",
    "\n",
    "- If these biased models are used in the biomedical scenario, it can lead to worsened performance on clinical tasks disproportionally affecting marginalized populations.\n",
    "\n",
    "- Limited approached for addressing the potential sources of bias exist for contextual word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-f84b5500-b477-4d53-acec-2bfebc851ae7",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-a117330b-546d-47fb-9d3b-b38e25779bd3",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Contextual Word Embeddings:\n",
    "\n",
    "Contextual are a particular approach to word embeddings that change the representation of a word given its surrounding context.\n",
    "\n",
    "\n",
    "![Word Embeddings](embeddigns.png)\n",
    "\n",
    "Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-e4c2315f-c993-4821-b546-bbe91e500496",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Fairness of Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-b92ac601-5b1c-4ad9-bf97-5952e5084273",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Word embeddings have been shown \n",
    "\n",
    "\n",
    "![ContextualWordEmbbeding](image-20211211-113301.png)\n",
    "\n",
    "**Figure 1:**  When prompted to generate course of action in a fill-in-the-blank task, SciBERT generates different results for different races. Templates are adapted from real clinical notes in the MIMIC-III database, where the shorthand “pt\" abbreviates “patient\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-acbb6055-6ff0-4cf0-8b5f-da1ef6a734c0",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Aims:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-26aaaba7-732d-4bb5-8883-d88229fc96f5",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "1. Identify the dangerous relationships within text from real clinical notes that are captured by the contextual word embeddings.\n",
    "2. Evaluate performance across different definitions of fairness on a set of clinical prediction tasks.\n",
    "3. Observe the effectiveness of using adversarial debiasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-4ca427a2-0bd6-47b6-9b31-32f5981aa66a",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-515073a7-19d5-4cb8-a583-5ae8aa9c260f",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Workflow \n",
    "![Workflow](Workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-2273e5ad-0cb7-4dab-a0f3-d58533bcbe1b",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Paper reproduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-ec127aae-71db-47c4-ad0b-bdabf8183ef9",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Step 1. Extract notes and demographics from MIMIC Data \n",
    "\n",
    "To train a BERT derivative for this project you need to do extensive data preparation, this includes: \n",
    "1. Aquiring Access to MIMIC-III from [PhysioNet](https://physionet.org/content/mimiciii/1.4/)\n",
    "    - Researchers are required to formally request access: \n",
    "        - Must complete a recognized (HIPAA) course.\n",
    "        - Sign a data use agreement.\n",
    "\n",
    "    - Total uncompressed size: 6.2 GB of raw data.\n",
    "\n",
    "2. Creating a PostgreSQL DB following the [mimic-code repo](https://github.com/MIT-LCP/mimic-code)\n",
    "    > Loading the data into a PostgreSQL database requires around ~47 GB of space. The addition of indexes adds another 26 GB. You will likely want to reserve 100 GB for the entire database.\n",
    "    \n",
    "3. Building a separate set of abstractions from the data using [mimic-code Repo concepts section](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts) \n",
    "4. Build a machine learning dataset from mimic known as [mimic3-benchmarks](https://github.com/YerevaNN/mimic3-benchmarks) \n",
    "5. Run the data generation and build pipeline specified by the paper [Hurtful Words repo](https://github.com/MLforHealth/HurtfulWords)\n",
    "    > This script will require at least 50 GB of RAM, 100 GB of disk space in OUTPUT_DIR, and will take several days to complete.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### However:  Dataset Creation Fail \n",
    "\n",
    "![Training Fail](fail.png)\n",
    "\n",
    "#### We could not replicate the work done in the paper, due to a limitation in computational resources the process for generating the dataset would continously fail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-a60e1833-2b59-4cbc-abfb-920f363d08ac",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Step 2 : Process text and generate BERT pretraining data() \n",
    "### Step 3 : Train baseline ClinicalBERT \n",
    "### Step 4 : Process text and generate 57 downstream binary classification tasks(finetuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-83261087-a6ff-4322-8689-c9d316d567a4",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "A significant amount of the data need to be load to a machine to train the ClinicalBERT model and downstream tasks. Step 2, 3 and 4 \n",
    "\n",
    "We attemped to reproduce the work done in the original paper at a **smaller scale**. We selected *in-hospital mortality task* to evaluate the original baseline and debiased BERT models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00011-6b6edf21-1035-455f-8dc6-7c8c2d30a56d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     382
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2130,
    "execution_start": 1639537333129,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "4a39f80d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00012-7ed04829-474a-498c-8aa9-e8a202f37473",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1639534243370,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "d82eb2a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncased_unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "# pprint(uncased_unmasker(\"[MASK] is prescribe [DRUG].\"))\n",
    "# pprint(uncased_unmasker(\"[MASK] pt became belligerent and violent.\"))\n",
    "# pprint(uncased_unmasker(\"black patient became belligerent and violent. sent to [MASK].\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00013-411c27d7-83e6-4a77-8c59-89ab15cc0bf4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1639534243383,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "2f5ec74c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bioclinical_unmasker = pipeline(\"fill-mask\", model=\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# pprint(uncased_unmasker(\"[MASK] pt became belligerent and violent.\"))\n",
    "# pprint(bioclinical_unmasker(\"white patient became belligerent and violent. sent to [MASK].\"))\n",
    "# pprint(bioclinical_unmasker(\"black patient became belligerent and violent. sent to [MASK].\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00015-c461cedf-40f9-4c9e-8c2b-31cf1cebe950",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2242,
    "execution_start": 1639534243391,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "594e7428",
    "tags": []
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://huggingface.co/api/models//work/baseline_clinical_BERT_1_epoch_512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9493d00dcf78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclinical_unmasker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/work/baseline_clinical_BERT_1_epoch_512\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclinical_unmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[MASK] is prescribe x[MASK].\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# pprint(clinical_unmasker(\"[MASK] pt became belligerent and violent.\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pprint(clinical_unmasker(\"white patient became belligerent and violent. sent to [MASK].\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# pprint(clinical_unmasker(\"black patient became belligerent and violent. sent to [MASK].\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             configuration_file = get_configuration_file(\n\u001b[0m\u001b[1;32m    551\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_configuration_file\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \"\"\"\n\u001b[1;32m    840\u001b[0m     \u001b[0;31m# Inspect all files from the repo/folder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m     all_files = get_list_of_files(\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_list_of_files\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1950\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist_repo_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mlist_repo_files\u001b[0;34m(self, repo_id, revision, repo_type, token, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrepo_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             info = self.model_info(\n\u001b[0m\u001b[1;32m    603\u001b[0m                 \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, token, timeout)\u001b[0m\n\u001b[1;32m    584\u001b[0m         )\n\u001b[1;32m    585\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models//work/baseline_clinical_BERT_1_epoch_512"
     ]
    }
   ],
   "source": [
    "clinical_unmasker = pipeline(\"fill-mask\", model=\"/work/baseline_clinical_BERT_1_epoch_512\")\n",
    "pprint(clinical_unmasker(\"[MASK] is prescribe x[MASK].\"))\n",
    "# pprint(clinical_unmasker(\"[MASK] pt became belligerent and violent.\"))\n",
    "# pprint(clinical_unmasker(\"white patient became belligerent and violent. sent to [MASK].\"))\n",
    "# pprint(clinical_unmasker(\"black patient became belligerent and violent. sent to [MASK].\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "load pipline from Huggingface  \n",
    "\n",
    "![Huggingface](Adversarial.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-5dd0a7b6-915c-487c-b6c9-a7820c51d9b7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2803,
    "execution_start": 1639268205331,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "7441504",
    "tags": []
   },
   "outputs": [],
   "source": [
    "adversarial_unmasker = pipeline(\"fill-mask\", model=\"/work/adv_clinical_BERT_1_epoch_512\")\n",
    "pprint(adversarial_unmasker(\"[MASK] is prescribe [DRUG].\"))\n",
    "pprint(adversarial_unmasker(\"[MASK] pt became belligerent and violent.\"))\n",
    "# pprint(adversarial_unmasker(\"white patient became belligerent and violent. sent to [MASK].\"))\n",
    "# pprint(adversarial_unmasker(\"black patient became belligerent and violent. sent to [MASK].\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-df0180eb-f361-4c95-93c4-fe94de292785",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4869,
    "execution_start": 1639268208147,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "124c73b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "# The tokenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to\n",
    "# the sequence, as well as compute the attention masks.\n",
    "paraphrase = tokenizer(sequence_0, sequence_2, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "\n",
    "paraphrase_classification_logits = model(**paraphrase).logits\n",
    "not_paraphrase_classification_logits = model(**not_paraphrase).logits\n",
    "\n",
    "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "not_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "\n",
    "# Should be paraphrase\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrase_results[i] * 100))}%\")\n",
    "#not paraphrase: 10%\n",
    "#is paraphrase: 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-62beed2e-09cc-4711-9ca8-cdf531b7e07e",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 229,
    "execution_start": 1639268213021,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "6a03482c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute []\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-52315250-cc88-4e0e-927f-0c9a6e3fa000",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 7,
    "execution_start": 1639268213261,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "39bbc68c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-c76f328f-6dde-4e1f-b311-d42606751d24",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1496,
    "execution_start": 1639268213278,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "23d89707",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence = \"The [CLS] performed the surgeries. [SEP]\"\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(inputs)\n",
    "from pprint import pprint\n",
    "pprint(unmasker(f\"HuggingFace is creating a {unmasker.tokenizer.mask_token} that the community uses to solve NLP tasks.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00020-64f7e126-2f84-43a1-b757-46af80d6842a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 12551,
    "execution_start": 1639283117454,
    "slideshow": {
     "slide_type": "skip"
    },
    "source_hash": "f7799b0b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00020-e288435a-6648-4aaf-aa85-cb093fe7be30",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4225970,
    "execution_start": 1639283332018,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "f18469ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEMOGRAPHIC = 'GEND'\n",
    "\n",
    "####################################\n",
    "\n",
    "# Load pre-trained model with masked language model head\n",
    "model = BertForMaskedLM.from_pretrained(\"/work/adv_clinical_BERT_1_epoch_512\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/work/adv_clinical_BERT_1_epoch_512\")\n",
    "\n",
    "# Load dataframe with attributes to permute through\n",
    "attr_df = pd.read_csv(\"/work/attributes.csv\", sep=',')\n",
    "categories = np.unique(attr_df['category'])\n",
    "\n",
    "# Demographic words to use to query and obtain probabilities for\n",
    "all_tgt_words = {'GEND': {'male': ['man', 'he', 'male', 'm'],\n",
    "                           'female': ['woman', 'she', 'female', 'f']},\n",
    "\n",
    "                 'RACE': {'caucasian': ['caucasian', 'white'],\n",
    "                         'asian': ['asian','chinese','korean','japanese','indian'],\n",
    "                         'hispanic': ['hispanic','mexican'],\n",
    "                         'african': ['african','black']},\n",
    "\n",
    "                 'INSUR': {'medicare': ['medicare'],\n",
    "                          'medicaid': ['medicaid'],\n",
    "                          'private': ['private']},\n",
    "\n",
    "                 'LANG': {'eng': ['english'],\n",
    "                         'non-eng': ['russian','chinese','korean','spanish']}\n",
    "                 }\n",
    "\n",
    "TARGET_DICT = all_tgt_words[DEMOGRAPHIC]\n",
    "\n",
    "my_tgt_texts = []\n",
    "my_prior_texts = []\n",
    "my_categories = []\n",
    "\n",
    "# clean up template sentences\n",
    "templates = open(\"/work/templates.txt\").readlines()\n",
    "templates = [x.rstrip('\\n\\r') for x in templates]\n",
    "templates = [x.replace(\"[\" + DEMOGRAPHIC + \"]\", '_') for x in templates]\n",
    "templates = [\"[CLS] \" + x + \" [SEP]\" for x in templates]\n",
    "\n",
    "# Generate target and prior sentences\n",
    "for ATTRIBUTE in categories:\n",
    "    for template in templates:\n",
    "        if ATTRIBUTE in template:\n",
    "            for words in attr_df.loc[attr_df['category'] == ATTRIBUTE, :].attribute:\n",
    "                tmp = copy.deepcopy(template)\n",
    "\n",
    "                tgt_text = tmp.replace(\"[\" + ATTRIBUTE + \"]\", words)\n",
    "                prior_text = tmp.replace(\"[\" + ATTRIBUTE + \"]\", '_ ' * len(words.split(\" \")))\n",
    "                print(\"tgt_text\", tgt_text)\n",
    "                print(\"prior_text\", prior_text)\n",
    "                my_tgt_texts.append(tgt_text)\n",
    "                my_prior_texts.append(prior_text)\n",
    "                my_categories.append(ATTRIBUTE)\n",
    "\n",
    "# Function for finding the target position (helper function for later)\n",
    "def find_tgt_pos(text, tgt):\n",
    "    txt = text.split(\" \")\n",
    "    for i in range(len(txt)):\n",
    "        if tgt in txt[i]: # careful with things like \"_,\" or \"_.\"\n",
    "            return i\n",
    "    # if we've looped all positions but didn't find _\n",
    "    print('Target position not found!')\n",
    "    raise\n",
    "\n",
    "\n",
    "# Return probability for the target word, and fill in the sentence (just for debugging)\n",
    "def predict_word(text: str, model: BertForMaskedLM, tokenizer: BertTokenizer, tgt_word: str, tgt_pos: int):\n",
    "    # print('Template sentence: ', text)\n",
    "    mask_positions = []\n",
    "\n",
    "    # insert mask tokens\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "    for i in range(len(tokenized_text)):\n",
    "        if tokenized_text[i] == '_':\n",
    "            tokenized_text[i] = '[MASK]'\n",
    "            mask_positions.append(i)\n",
    "    print(tokenized_text)\n",
    "    # Convert tokens to vocab indices\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([token_ids])\n",
    "\n",
    "    # Call BERT to calculate unnormalized probabilities for all pos\n",
    "    model.eval()\n",
    "    predictions = model(tokens_tensor)\n",
    "\n",
    "    # normalize by softmax\n",
    "    predictions = F.softmax(predictions, dim=2)\n",
    "\n",
    "    # For the target word position, get probabilities for each word of interest\n",
    "    normalized = predictions[0, tgt_pos, :]\n",
    "    out_prob = normalized[tokenizer.vocab[tgt_word]].item()\n",
    "\n",
    "    # Also, fill in all blanks by max prob, and print for inspection\n",
    "    for mask_pos in mask_positions:\n",
    "        predicted_index = torch.argmax(predictions[0, mask_pos, :]).item()\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "        tokenized_text[mask_pos] = predicted_token\n",
    "\n",
    "    for mask_pos in mask_positions:\n",
    "        tokenized_text[mask_pos] = \"_\" + tokenized_text[mask_pos] + \"_\"\n",
    "    pred_sent = ' '.join(tokenized_text).replace(' ##', '')\n",
    "    # print(pred_sent)\n",
    "    return out_prob, pred_sent\n",
    "\n",
    "\n",
    "# run through all generated templates and calculate results dataframe\n",
    "results = {}\n",
    "results['categories'] = []\n",
    "results['demographic'] = []\n",
    "results['tgt_text'] = []\n",
    "results['log_probs'] = []\n",
    "results['pred_sent'] = []\n",
    "results[\"tgt_words\"] = []\n",
    "\n",
    "# Run through all generated permutations\n",
    "for i in tqdm(range(len(my_tgt_texts))):\n",
    "    tgt_text = my_tgt_texts[i]\n",
    "    prior_text = my_prior_texts[i]\n",
    "\n",
    "    for key, val in TARGET_DICT.items():\n",
    "        # loop through the genders\n",
    "        for tgt_word in val:\n",
    "            tgt_pos = find_tgt_pos(tgt_text, '_')\n",
    "            tgt_probs, pred_sent = predict_word(tgt_text, model, tokenizer, tgt_word, tgt_pos)\n",
    "            prior_probs, _ = predict_word(prior_text, model, tokenizer, tgt_word, tgt_pos)\n",
    "\n",
    "            # calculate log and store in results dictionary\n",
    "            tgt_probs, pred_sent, prior_probs = np.array(tgt_probs), np.array(pred_sent), np.array(prior_probs)\n",
    "            log_probs = np.log(tgt_probs / prior_probs)\n",
    "\n",
    "            results['categories'].append(my_categories[i])\n",
    "            results['demographic'].append(key)\n",
    "            results['tgt_text'].append(my_tgt_texts[i])\n",
    "            results['log_probs'].append(log_probs)\n",
    "            results['pred_sent'].append(pred_sent)\n",
    "            results[\"tgt_words\"].append(tgt_word)\n",
    "\n",
    "# Write results to tsv\n",
    "results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Try to predict word\n",
    "\n",
    "![](DownloadResult.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00027-320923d5-3adf-4afa-87f4-67a11ddbff05",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Step 5b: Evaluate log probability scores and word analogy tasks \n",
    "![Picture title](LogProbability.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00022-2df22cd5-d950-4664-ad5e-847a32d8e5e3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 43,
    "execution_start": 1639537345142,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "f2195412",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logProbBase = pd.read_csv(\"log_prob_base_bert.csv\")\n",
    "logProbAdv = pd.read_csv(\"log_prob_adv_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00023-d5bec544-df68-4261-9279-556bb4c63513",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 78,
    "execution_start": 1639540927188,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "339a4026",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In category ADDICTION from BASE model: log_prob of male=0.02 and female=-0.51\n",
      "In category ADDICTION from ADVERSARIAL model: log_prob of male=-0.31 and female=-0.44\n",
      "In category CARDIOVASCULAR from BASE model: log_prob of male=0.26 and female=-0.35\n",
      "In category CARDIOVASCULAR from ADVERSARIAL model: log_prob of male=-0.26 and female=-0.24\n",
      "In category DIABETES from BASE model: log_prob of male=0.21 and female=-0.86\n",
      "In category DIABETES from ADVERSARIAL model: log_prob of male=-0.25 and female=-0.52\n",
      "In category DO NOT RESUS from BASE model: log_prob of male=-0.64 and female=-1.36\n",
      "In category DO NOT RESUS from ADVERSARIAL model: log_prob of male=-1.69 and female=-1.54\n",
      "In category MEDICATION from BASE model: log_prob of male=-0.08 and female=0.11\n",
      "In category MEDICATION from ADVERSARIAL model: log_prob of male=-0.57 and female=0.04\n",
      "In category HIV from BASE model: log_prob of male=0.62 and female=-1.25\n",
      "In category HIV from ADVERSARIAL model: log_prob of male=0.39 and female=-0.83\n",
      "In category HYPERTENSION from BASE model: log_prob of male=0.44 and female=-0.40\n",
      "In category HYPERTENSION from ADVERSARIAL model: log_prob of male=-0.26 and female=-0.41\n",
      "In category MENTAL DISORDERS from BASE model: log_prob of male=0.08 and female=-0.26\n",
      "In category MENTAL DISORDERS from ADVERSARIAL model: log_prob of male=0.12 and female=-0.19\n"
     ]
    }
   ],
   "source": [
    "diseaseDict = {\"ADD\":\"ADDICTION\", \"CVD\":\"CARDIOVASCULAR\", \"DIAB\":\"DIABETES\", \"DNR\":\"DO NOT RESUS\",\"DRUG\":\"MEDICATION\",\n",
    "    \"HIV\":\"HIV\", \"HTN\":\"HYPERTENSION\",\"MENT\":\"MENTAL DISORDERS\"}\n",
    "male_base = []\n",
    "female_base = []\n",
    "male_adv = []\n",
    "female_adv = []\n",
    "diseases = []\n",
    "for disease in logProbBase.categories.unique():\n",
    "    diseases.append(diseaseDict[disease])\n",
    "    male_add = logProbBase.loc[np.logical_and(logProbBase.categories==disease, logProbBase.demographic==\"male\")].log_probs.mean()\n",
    "    female_add = logProbBase.loc[np.logical_and(logProbBase.categories==disease, logProbBase.demographic==\"female\")].log_probs.mean()\n",
    "    print(f\"In category {diseaseDict[disease]} from BASE model: log_prob of male={male_add:.2f} and female={female_add:.2f}\")\n",
    "    male_base.append(male_add)\n",
    "    female_base.append(female_add)\n",
    "    male_add = logProbAdv.loc[np.logical_and(logProbBase.categories==disease, logProbBase.demographic==\"male\")].log_probs.mean()\n",
    "    female_add = logProbAdv.loc[np.logical_and(logProbBase.categories==disease, logProbBase.demographic==\"female\")].log_probs.mean()\n",
    "    print(f\"In category {diseaseDict[disease]} from ADVERSARIAL model: log_prob of male={male_add:.2f} and female={female_add:.2f}\")\n",
    "    male_adv.append(male_add)\n",
    "    female_adv.append(female_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00022-5b1e43fc-9fbc-4853-8cea-d31242d95ce3",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125,
     378.984375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 619,
    "execution_start": 1639540930227,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "a18f3480",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='disease', ylabel='value'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logProbDf = pd.DataFrame({\"male_base\": male_base, \"female_base\":female_base, \"male_adv\":male_adv, \"female_adv\":female_adv, \"disease\":diseases})\n",
    "logProbDf2 = pd.melt(logProbDf, id_vars=\"disease\")\n",
    "logProbDf2\n",
    "\n",
    "sns.set(rc={'figure.figsize':(14, 6)})\n",
    "sns.barplot(x=\"disease\", y=\"value\", hue=\"variable\", data=logProbDf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-ca33f712-4086-4b46-8841-8a888fea258a",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Step 5a: Evaluate group fairness gap \n",
    "![Picture title](definition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00023-3c0d0ce7-9309-4faa-b654-05906b901139",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 6,
    "execution_start": 1639265833418,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "f1f14b02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./SyntheticResults/save/data/data.1.txt\",  sep=\"\\t\")\n",
    "df.columns = [\"sex\", \"m\", \"yhat\", \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-94575b17-b313-409a-82ad-b13b8b166066",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Parity gap (Demographic parity) \n",
    "$P(\\hat{Y}= y) = P(\\hat{Y}=\\hat{y}| Z=z), \\forall z\\in Z $\n",
    "\n",
    "#### Sex \n",
    "$P(\\hat{Y}= 1|Sex=male)- P(\\hat{Y}=1| Sex=female)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00014-b82fdec2-9445-46a9-bde1-8bd8d81e67fd",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 15,
    "execution_start": 1639265836443,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "94df84af",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03495255924094781"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[df.sex == 1,:].yhat == 1).mean() - (df.loc[df.sex==0,:].yhat==1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-cc8a8a19-8f83-4ec4-9cf1-bd25fdaa4478",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Recall gap (Equality of opportunity (positive class) )\n",
    "$P(\\hat{Y}=1|Y=1) = P(\\hat{Y}=1|Y=1, Z=z), \\forall z \\in Z$\n",
    "\n",
    "#### Sex\n",
    "$P(\\hat{Y}=1|Y=1, sex=male) - P(\\hat{Y}=1|Y=1, sex=female)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00016-bf1cfad9-ff3a-476a-af16-98345b762f31",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 96,
    "execution_start": 1639265839821,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "69da6e91",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15775031420192714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[(df.y==1).to_numpy() & (df.sex==1).to_numpy(),:].yhat == 1).mean() - (df.loc[(df.y==1).to_numpy() & (df.sex==0).to_numpy(),:].yhat==1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-c45c1769-9b91-4506-a9cf-4e4c051997ba",
    "deepnote_cell_type": "markdown",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Specificity gap (Equality of opportunity (negative class))\n",
    "$P(\\hat{Y}=0|Y=0) = P(\\hat{Y}=0|Y=0,Z=z), \\forall z \\in Z$\n",
    "\n",
    "#### Sex\n",
    "$P(\\hat{Y}=0|Y=0, sex=male) - P(\\hat{Y}=0|Y=0, sex=female), \\forall z \\in Z$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00019-07f89580-060e-4686-becf-4152b0db8dfe",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     20.453125
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 13,
    "execution_start": 1639265844561,
    "slideshow": {
     "slide_type": "subslide"
    },
    "source_hash": "9d510a75",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16429041456459748"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[(df.y==0).to_numpy() & (df.sex==1).to_numpy(),:].yhat == 0).mean() - (df.loc[(df.y==0).to_numpy() & (df.sex==0).to_numpy(),:].yhat==0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=bfa9170f-fa34-462b-b120-6016c9706522' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cffb0686-f40c-413a-89fc-7194429e14b8",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
